{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/'\n",
    "daily='csse_covid_19_daily_reports/' #+date in the form  01-22-2020.csv\n",
    "time_serie='csse_covid_19_time_series/' #+confirmed, death,recovered\n",
    "confirmed_data='time_series_covid19_confirmed_global.csv'\n",
    "death_data='time_series_covid19_deaths_global.csv'\n",
    "recovered_data='time_series_covid19_recovered_global.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12\n",
      "03-04-2020\n",
      "2020-03-04\n"
     ]
    }
   ],
   "source": [
    "def make_date(day,month):   #convert a date in (day,month) format to a string to feed in the read_csv function\n",
    "    day=str(day)\n",
    "    month=str(month)\n",
    "    if len(day)==1:\n",
    "        day='0'+day\n",
    "    if len(month)==1:\n",
    "        month='0'+month \n",
    "    date=month+'-'+day+'-2020'\n",
    "    return date\n",
    "today = str(date.today())\n",
    "print(today)\n",
    "a=int(today[5])\n",
    "b=int(today[6])\n",
    "c=int(today[8])\n",
    "d=int(today[9])\n",
    "today=make_date(a+b,c+d)\n",
    "print(today)\n",
    "def add_xday(a,b,c,d,x):\n",
    "    day=a*10+b\n",
    "    month=10*c+d\n",
    "    if month==4 or month==6:\n",
    "        endmonth=30\n",
    "    else:\n",
    "        endmonth=31\n",
    "    newday=day+x\n",
    "    if newday>endmonth:\n",
    "        month+=1\n",
    "        newday=newday-endmonth\n",
    "    return make_date(newday,month)\n",
    "\n",
    "def subdate (date):\n",
    "    a=date[0]\n",
    "    b=date[1]\n",
    "    c=date[3]\n",
    "    d=date[4]\n",
    "    return '2020-'+a+b+'-'+c+d\n",
    "print(subdate(today))\n",
    "todayplus2=add_xday(a,b,c,d,2)\n",
    "todayplusweek=add_xday(a,b,c,d,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/2/20</th>\n",
       "      <th>4/3/20</th>\n",
       "      <th>4/4/20</th>\n",
       "      <th>4/5/20</th>\n",
       "      <th>4/6/20</th>\n",
       "      <th>4/7/20</th>\n",
       "      <th>4/8/20</th>\n",
       "      <th>4/9/20</th>\n",
       "      <th>4/10/20</th>\n",
       "      <th>4/11/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>281</td>\n",
       "      <td>299</td>\n",
       "      <td>349</td>\n",
       "      <td>367</td>\n",
       "      <td>423</td>\n",
       "      <td>444</td>\n",
       "      <td>484</td>\n",
       "      <td>521</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277</td>\n",
       "      <td>304</td>\n",
       "      <td>333</td>\n",
       "      <td>361</td>\n",
       "      <td>377</td>\n",
       "      <td>383</td>\n",
       "      <td>400</td>\n",
       "      <td>409</td>\n",
       "      <td>416</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>986</td>\n",
       "      <td>1171</td>\n",
       "      <td>1251</td>\n",
       "      <td>1320</td>\n",
       "      <td>1423</td>\n",
       "      <td>1468</td>\n",
       "      <td>1572</td>\n",
       "      <td>1666</td>\n",
       "      <td>1761</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>428</td>\n",
       "      <td>439</td>\n",
       "      <td>466</td>\n",
       "      <td>501</td>\n",
       "      <td>525</td>\n",
       "      <td>545</td>\n",
       "      <td>564</td>\n",
       "      <td>583</td>\n",
       "      <td>601</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n",
       "1            NaN        Albania  41.1533  20.1683        0        0        0   \n",
       "2            NaN        Algeria  28.0339   1.6596        0        0        0   \n",
       "3            NaN        Andorra  42.5063   1.5218        0        0        0   \n",
       "4            NaN         Angola -11.2027  17.8739        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  4/2/20  4/3/20  4/4/20  4/5/20  4/6/20  \\\n",
       "0        0        0        0  ...     273     281     299     349     367   \n",
       "1        0        0        0  ...     277     304     333     361     377   \n",
       "2        0        0        0  ...     986    1171    1251    1320    1423   \n",
       "3        0        0        0  ...     428     439     466     501     525   \n",
       "4        0        0        0  ...       8       8      10      14      16   \n",
       "\n",
       "   4/7/20  4/8/20  4/9/20  4/10/20  4/11/20  \n",
       "0     423     444     484      521      555  \n",
       "1     383     400     409      416      433  \n",
       "2    1468    1572    1666     1761     1825  \n",
       "3     545     564     583      601      601  \n",
       "4      17      19      19       19       19  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmed=pd.read_csv(url+time_serie+confirmed_data)\n",
    "dead=pd.read_csv(url+time_serie+death_data)\n",
    "recovered=pd.read_csv(url+time_serie+recovered_data)\n",
    "country=confirmed[['Province/State','Country/Region']]\n",
    "confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_us=pd.read_csv('pop_us.csv')\n",
    "pop_us=pop_us[['State','Pop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell save the data for the us in a dictionary us_data. Pay attention to adjuste to if statement to\n",
    "#adjust it at the current date. The value of the dict are dataframe with: first ligne:confirme case, second: dead, \n",
    "#third: recovered. the columns are the different dates\n",
    "us_data={}\n",
    "total_state=[]\n",
    "for month in range(1,5):\n",
    "    for day in range(1,32):\n",
    "        if month==1 and day<23:\n",
    "            pass\n",
    "        elif month==2 and day>29:\n",
    "            pass\n",
    "        elif month==4 and day>9:\n",
    "            pass\n",
    "        else:\n",
    "            dat=make_date(day,month)\n",
    "            #print(dat)\n",
    "            today=pd.read_csv(url+daily+dat+'.csv')\n",
    "            if month<3 or (month==3 and day<22):\n",
    "                st='Province/State'\n",
    "                country='Country/Region'\n",
    "            else:\n",
    "                st='Province_State'\n",
    "                country='Country_Region'\n",
    "            for i, state in enumerate(today[st]):\n",
    "                if today[country].iloc[i]!='US':\n",
    "                    pass\n",
    "                else:\n",
    "                    if state not in total_state:\n",
    "                        total_state.append(state)\n",
    "                        us_data[state]=pd.DataFrame()\n",
    "                        us_data[state][dat]=np.array([today['Confirmed'].iloc[i],today['Deaths'].iloc[i],today['Recovered'].iloc[i]])\n",
    "                    elif dat not in us_data[state].columns:\n",
    "                        us_data[state][dat]=np.array([today['Confirmed'].iloc[i],today['Deaths'].iloc[i],today['Recovered'].iloc[i]])\n",
    "                    else:\n",
    "                        us_data[state][dat]+=np.array([today['Confirmed'].iloc[i],today['Deaths'].iloc[i],today['Recovered'].iloc[i]])\n",
    "                        \n",
    "                    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_us=us_data.keys()\n",
    "pop_keys=pop_us['State']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Province          Pop\n",
      "0        Guangdong  104,303,132\n",
      "1         Shandong  100,063,065\n",
      "2            Henan   94,023,567\n",
      "3          Sichuan   80,418,200\n",
      "4          Jiangsu   78,659,903\n",
      "5            Hebei   71,854,202\n",
      "6            Hunan   65,683,722\n",
      "7            Anhui   59,500,510\n",
      "8            Hubei   57,237,740\n",
      "9         Zhejiang   54,426,891\n",
      "10         Guangxi   46,026,629\n",
      "11          Yunnan   45,966,239\n",
      "12         Jiangxi   44,567,475\n",
      "13        Liaoning   43,746,323\n",
      "14          Fujian   36,894,216\n",
      "15         Shaanxi   37,327,378\n",
      "16    Heilongjiang   38,312,224\n",
      "17          Shanxi   37,022,111\n",
      "18         Guizhou   35,806,468\n",
      "19       Chongqing   28,846,170\n",
      "20           Jilin   27,462,297\n",
      "21           Gansu   25,575,254\n",
      "22  Inner Mongolia   24,706,321\n",
      "23        Xinjiang   21,813,334\n",
      "24        Shanghai   23,019,148\n",
      "25         Beijing   19,612,368\n",
      "26         Tianjin   12,938,224\n",
      "27          Hainan    9,261,518\n",
      "28       Hong Kong    7,061,200\n",
      "29         Ningxia    6,176,900\n",
      "30         Qinghai    5,626,722\n",
      "31           Tibet    3,002,166\n",
      "32           Macau      552,503\n"
     ]
    }
   ],
   "source": [
    "pop_china=pd.read_csv('pop_china.csv')\n",
    "print(pop_china)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anhui\n",
      "(array([7]),)\n",
      "59500510\n",
      "59500510.0\n",
      "--\n",
      "Beijing\n",
      "(array([25]),)\n",
      "19612368\n",
      "19612368.0\n",
      "--\n",
      "Chongqing\n",
      "(array([19]),)\n",
      "28846170\n",
      "28846170.0\n",
      "--\n",
      "Fujian\n",
      "(array([14]),)\n",
      "36894216\n",
      "36894216.0\n",
      "--\n",
      "Gansu\n",
      "(array([21]),)\n",
      "25575254\n",
      "25575254.0\n",
      "--\n",
      "Guangdong\n",
      "(array([0]),)\n",
      "104303132\n",
      "104303132.0\n",
      "--\n",
      "Guangxi\n",
      "(array([10]),)\n",
      "46026629\n",
      "46026629.0\n",
      "--\n",
      "Guizhou\n",
      "(array([18]),)\n",
      "35806468\n",
      "35806468.0\n",
      "--\n",
      "Hainan\n",
      "(array([27]),)\n",
      "9261518\n",
      "9261518.0\n",
      "--\n",
      "Hebei\n",
      "(array([5]),)\n",
      "71854202\n",
      "71854202.0\n",
      "--\n",
      "Heilongjiang\n",
      "(array([16]),)\n",
      "38312224\n",
      "38312224.0\n",
      "--\n",
      "Henan\n",
      "(array([2]),)\n",
      "94023567\n",
      "94023567.0\n",
      "--\n",
      "Hong Kong\n",
      "(array([28]),)\n",
      "7061200\n",
      "7061200.0\n",
      "--\n",
      "Hubei\n",
      "(array([8]),)\n",
      "57237740\n",
      "57237740.0\n",
      "--\n",
      "Hunan\n",
      "(array([6]),)\n",
      "65683722\n",
      "65683722.0\n",
      "--\n",
      "Inner Mongolia\n",
      "(array([22]),)\n",
      "24706321\n",
      "24706321.0\n",
      "--\n",
      "Jiangsu\n",
      "(array([4]),)\n",
      "78659903\n",
      "78659903.0\n",
      "--\n",
      "Jiangxi\n",
      "(array([12]),)\n",
      "44567475\n",
      "44567475.0\n",
      "--\n",
      "Jilin\n",
      "(array([20]),)\n",
      "27462297\n",
      "27462297.0\n",
      "--\n",
      "Liaoning\n",
      "(array([13]),)\n",
      "43746323\n",
      "43746323.0\n",
      "--\n",
      "Macau\n",
      "(array([32]),)\n",
      "552503\n",
      "552503.0\n",
      "--\n",
      "Ningxia\n",
      "(array([29]),)\n",
      "6176900\n",
      "6176900.0\n",
      "--\n",
      "Qinghai\n",
      "(array([30]),)\n",
      "5626722\n",
      "5626722.0\n",
      "--\n",
      "Shaanxi\n",
      "(array([15]),)\n",
      "37327378\n",
      "37327378.0\n",
      "--\n",
      "Shandong\n",
      "(array([1]),)\n",
      "100063065\n",
      "100063065.0\n",
      "--\n",
      "Shanghai\n",
      "(array([24]),)\n",
      "23019148\n",
      "23019148.0\n",
      "--\n",
      "Shanxi\n",
      "(array([17]),)\n",
      "37022111\n",
      "37022111.0\n",
      "--\n",
      "Sichuan\n",
      "(array([3]),)\n",
      "80418200\n",
      "80418200.0\n",
      "--\n",
      "Tianjin\n",
      "(array([26]),)\n",
      "12938224\n",
      "12938224.0\n",
      "--\n",
      "Tibet\n",
      "(array([31]),)\n",
      "3002166\n",
      "3002166.0\n",
      "--\n",
      "Xinjiang\n",
      "(array([23]),)\n",
      "21813334\n",
      "21813334.0\n",
      "--\n",
      "Yunnan\n",
      "(array([11]),)\n",
      "45966239\n",
      "45966239.0\n",
      "--\n",
      "Zhejiang\n",
      "(array([9]),)\n",
      "54426891\n",
      "54426891.0\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "X_china={}\n",
    "for i,land in enumerate(country['Country/Region']):\n",
    "    if land=='China':\n",
    "        \n",
    "        state=confirmed['Province/State'].iloc[i]\n",
    "        print(state)\n",
    "        a=np.where(pop_china['Province'] == state)\n",
    "        print(a)\n",
    "        a=pop_china['Pop'].iloc[a].values\n",
    "        a=str(a).replace(',','')\n",
    "        a=a.replace('[','')\n",
    "        a=a.replace(']','') \n",
    "        a=a.replace(\"'\",'')\n",
    "        print(a)\n",
    "        N=float(a)\n",
    "        print(N)\n",
    "        print('--')\n",
    "        length=len(confirmed.iloc[0,4:])\n",
    "        X=np.zeros((5,length))\n",
    "        X[0,:]=confirmed.iloc[i,4:]\n",
    "        X[1,:]=dead.iloc[i,4:]\n",
    "        X[2,:]=recovered.iloc[i,4:]\n",
    "        X[3,:]=N*np.ones_like(X[0,:])-X[0,:]-X[1,:]-X[2,:]\n",
    "        X[4,:]=X[3,:]*X[0,:]\n",
    "        X=X.reshape(1,-1,5)\n",
    "        X_china[state]=[]\n",
    "        X_china[state].append(X[:,:-2,:])\n",
    "        X_china[state].append(X[:,2:,:3])\n",
    "        X_china[state].append(X[:,-1,:])\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN  training for China\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 79, 30)            4320      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 79, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 79, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 79, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 79, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 79, 30)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 79, 3)             93        \n",
      "=================================================================\n",
      "Total params: 19,053\n",
      "Trainable params: 19,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(1, 5)\n",
      "Anhui\n",
      "Train on 1 samples\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 7s 7s/sample - loss: 551879296296677277696.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 212ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 173ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 198ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 253ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 302ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 194ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 178ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 218ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 191ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 138ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 172ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 211ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 130ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 184ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 200ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 172ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 146ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 171ms/sample - loss: 551879296296677277696.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 137ms/sample - loss: 551879296296677277696.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_21_input to have 3 dimensions, but got array with shape (1, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bd4162a18750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(X_china[state][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_china\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_china\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_china\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_china\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_china\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_21_input to have 3 dimensions, but got array with shape (1, 5)"
     ]
    }
   ],
   "source": [
    "shape=np.shape(X_china['Anhui'][0])[1]\n",
    "print(shape)\n",
    "model_china=Sequential()\n",
    "model_china.add(LSTM(units=30,return_sequences=True,input_shape=(shape,5)))\n",
    "model_china.add(Dropout(0.25))\n",
    "model_china.add(LSTM(units=30,return_sequences=True))\n",
    "model_china.add(Dropout(0.25))\n",
    "model_china.add(LSTM(units=30,return_sequences=True))\n",
    "model_china.add(Dropout(0.25))\n",
    "model_china.add(Dense(units=3, activation=partial(tf.nn.leaky_relu, alpha=0.01)))\n",
    "model_china.summary()\n",
    "model_china.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "for state in X_china.keys():\n",
    "    print(np.shape(X_china[state][2]))\n",
    "    print(state)\n",
    "    #print(X_china[state][0])\n",
    "    model_china.fit(X_china[state][0],X_china[state][1],epochs=20)\n",
    "    pred[state]=model_china.predict(X_china[state][2])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model_china.predict(X_china['Beijing'][0])\n",
    "X=X_china['Beijing'][1][0,:,0]\n",
    "print(X)\n",
    "times=np.arange(len(X))\n",
    "plt.figure()\n",
    "plt.plot(times,X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for state in X_china.keys():\n",
    "    plt.figure()\n",
    "    X=X_china[state][0][0,:,0]\n",
    "    time=np.arange(len(X))\n",
    "    plt.plot(time,X,label=state)\n",
    "    plt.show()\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
